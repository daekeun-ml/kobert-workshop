{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Naver Movie Review Sentiment Classification with KoBERT\n",
    "---\n",
    "\n",
    "In this tutorial, we focus on fine-tuning with the pre-trained BERT model to classify Naver movie review sentiment.\n",
    "\n",
    "Currently, the original author's KoBERT(Bi-directional Encoder Representations from Transformers) fine-tuning code does not work properly with the latest GluonNLP version. So we modified the code for Hands-on Lab by referring to the GluonNLP tutorial (See https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html).\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "1. Load the pre-trained KoBERT model ahd attach an additional layer for classification\n",
    "2. Pre-processing data for Naver Movie Sentiment Classification\n",
    "3. Fine-tuning the KoBERT\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## Optional: Background\n",
    "---\n",
    "BERT consists of 12 transformer layers for base model(110M parameters) and 24 transformer layers for large model(340M parameters).\n",
    "\n",
    "\n",
    "### Input Representation\n",
    "\n",
    "The following figure shows the input representation in BERT: \n",
    "\n",
    "![bert-embed](./imgs/bert-embed.png)\n",
    "\n",
    "- ***Token Embedding***: Word embedding as a token meaning expression.\n",
    "- ***Segment Embedding*** For the purpose of connecting sentence-sentence (divided by Token A and Token B), different values are assigned depending on the token type and the type of input sentence.\n",
    "- ***Position Embedding***: The purpose is to give the token sequential meaning. Unlike Positional Encoding, which has a fixed value parameter for position, Positional Embedding changes position information through training.\n",
    "\n",
    "\n",
    "### Special Tokens\n",
    "\n",
    "- `[SEP]`: An identifier token that indicates the end of a sentence and is also used to distinguish two sentences. (e.g. `[SEP]` after token A, `[SEP]` after token B). Note that this token is still required while having only single-sentence\n",
    "\n",
    "- `[CLS]`: The first token is always `[CLS]` (class token) and is used to solve the `IsNext / NotNext` classification problem for pre-training. It is used for classification task in fine-tuning.\n",
    "\n",
    "\n",
    "### Byte-pair Encoding(BPE)\n",
    "\n",
    "The more vocabulary you have, the more computational complexity. If the number of vocabularies is limited, however,  there are many unregistered words, which inevitably degrades the language representation. (i,e. Out of Vocabulary; OOV) The way to solve this is word segmentation by separating existing words.\n",
    "\n",
    "Byte-pair Encoding(BPE) uses a bottom-up approach that gradually creates a vocabulary in units of characters. First, the words in the training data are made up of vocabulary in all letters or unicode units, and the most common unigrams are combined into a single unigram.\n",
    "\n",
    "Let us give you a simple example. If you count the frequency of each word from some training data and save it as a dictionary (key: word, value: frequency), the result is as follows.\n",
    "\n",
    "- `low : 5, lower : 2, newest : 6, widest : 3`\n",
    "\n",
    "If all words of a dictionary are separated into letters (chracter), the result is as follows.\n",
    "- `l o w : 5,  l o w e r : 2,  n e w e s t : 6,  w i d e s t : 3`\n",
    "- `vocab: l, o, w, e, r, n, w, s, t, i, d`\n",
    "\n",
    "1st iteration: Since the pair of unigrams with the highest frequency is `(e, s)`, we merge them into `es`.\n",
    "- `l o w : 5, l o w e r : 2, n e w es t : 6, w i d es t : 3`\n",
    "- `vocab: l, o, w, e, r, n, w, s, t, i, d, es`\n",
    "\n",
    "2nd iteration: Since the pair of unigrams with the highest frequency is `(es, t)`, we merge them into `est`.\n",
    "- `l o w : 5, l o w e r : 2, n e w est : 6, w i d est : 3`\n",
    "- `vocab: l, o, w, e, r, n, w, s, t, i, d, es, est`\n",
    "\n",
    "After a few iteration, we get:\n",
    "- `low : 5, low e r : 2, newest : 6, widest : 3`\n",
    "- `vocab: l, o, w, e, r, n, w, s, t, i, d, es, est, lo, low, ne, new, newest, wi, wid, widest`\n",
    "\n",
    "If the word `'lowest'` appeared during the test phase, it would have been a word for OOV, but in the above set of words using the BPE algorithm, `'lowest'` is no longer OOV. The machine first divides the `'lowest'` into letters. That is, `'l, o, w, e, s, t'`. And the machine finds `'low'` and `'est'` with reference to the above word set. That is, the machine encodes 'lowest' as two words `'low'` and `'est'`.\n",
    "\n",
    "\n",
    "### GELU(Gaussian Error Linear Units) Activation Function\n",
    "\n",
    "- Combined ReLU + Dropout; Stochastically multiply the input by 0 or 1 and apply the activation function.\n",
    "- It transmits a slight gradient even for negative values.\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x)=x\\Phi(x)=0.5x\\left(1+\\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)\\simeq 0.5x\\left(1+\\text{tanh}\\left(\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3)\\right)\\right), \\\\\\text{ where } \\Phi(x) \\text{ is the cumulative distribution function of } \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "## 1. Load Pre-trained Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install/Update Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', 'gluonnlp', 'torch', 'sentencepiece', 'tqdm', \n",
    "                 'onnxruntime', 'transformers', 'git+https://git@github.com/SKTBrain/KoBERT.git@master'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import nn, rnn\n",
    "from mxnet import nd, gluon, autograd\n",
    "import gluonnlp as nlp\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from model import get_mxnet_kobert_model\n",
    "from kobert.utils import get_tokenizer\n",
    "from bert import BERTDatasetTransform, BERTDataset, BERTClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume you have at least one GPU. Of course, GPU is not required when deploying a trained model, but it is very slow without a GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = mx.context.num_gpus()\n",
    "#num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pre-trained KoBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize BERT Classifier\n",
    "We only need one addiational `Dense` layer for classification task.\n",
    "GluonNLP's `model` class supports the `BERTClassifier()`, so you can easily add the classifier layer in one line. Of course, you can implement your own class. See `src/bert.py` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier = nlp.model.BERTClassifier(bert_base, num_classes=2, dropout=0.5)\n",
    "#bert_classifier = BERTClassifier(bert_base, num_classes=2, dropout=0.5)\n",
    "\n",
    "# Only need to initialize the classifier layer.\n",
    "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "bert_classifier.hybridize(static_alloc=True)\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = gluon.loss.SoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): DotProductSelfAttentionCell(\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): PositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(8002 -> 768, float32)\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.5, axes=())\n",
      "    (1): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bert_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Preparing the Dataset\n",
    "---\n",
    "\n",
    "Naver Movie Review data is publicly available at https://github.com/e9t/nsmc/ and consists of 150,000 training data and 50,000 test data. This data is often used for NLP benchmarking like IMDB review data in Korea. Sample data is shown below.\n",
    "\n",
    "![naver-movieembed](./imgs/naver-movie-sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-20 11:28:24--  https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.1, 2620:100:601c:1::a27d:601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/374ftkec978br3d/ratings_train.txt [following]\n",
      "--2020-05-20 11:28:25--  https://www.dropbox.com/s/dl/374ftkec978br3d/ratings_train.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com/cd/0/get/A4FTSoL6Pm25UKnNATp7zS3PpxLNvYZvOOxW9vhIIwWP-PCrBLbYRVs0qr-FThhjP5xlBLgJW0i6O5Ecwx7UtveBCqyyNzcU_VuOrYC0DqJUtJDizKATLYJ_ZQzYDSQlHfw/file?dl=1# [following]\n",
      "--2020-05-20 11:28:25--  https://uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com/cd/0/get/A4FTSoL6Pm25UKnNATp7zS3PpxLNvYZvOOxW9vhIIwWP-PCrBLbYRVs0qr-FThhjP5xlBLgJW0i6O5Ecwx7UtveBCqyyNzcU_VuOrYC0DqJUtJDizKATLYJ_ZQzYDSQlHfw/file?dl=1\n",
      "Resolving uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com (uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com)... 162.125.6.6, 2620:100:601c:6::a27d:606\n",
      "Connecting to uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com (uccccc63e56e2e1470aa07e29329.dl.dropboxusercontent.com)|162.125.6.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [application/binary]\n",
      "Saving to: ‘train.txt’\n",
      "\n",
      "train.txt           100%[===================>]  13.95M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2020-05-20 11:28:26 (196 MB/s) - ‘train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2020-05-20 11:28:26--  https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.1, 2620:100:601c:1::a27d:601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/977gbwh542gdy94/ratings_test.txt [following]\n",
      "--2020-05-20 11:28:26--  https://www.dropbox.com/s/dl/977gbwh542gdy94/ratings_test.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com/cd/0/get/A4EA1WvXkMHCUJN87o0NVnd8HcWoJXtR1xN9scfBgB1AVI0jM_0RpsPv7QQFZVY02vOo3TfaDY9C0mIbUmzlXbeG0q5KwDEdlD3wEDGjEm2HMbw7aFV8x_CVYmmjQU5at9E/file?dl=1# [following]\n",
      "--2020-05-20 11:28:26--  https://uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com/cd/0/get/A4EA1WvXkMHCUJN87o0NVnd8HcWoJXtR1xN9scfBgB1AVI0jM_0RpsPv7QQFZVY02vOo3TfaDY9C0mIbUmzlXbeG0q5KwDEdlD3wEDGjEm2HMbw7aFV8x_CVYmmjQU5at9E/file?dl=1\n",
      "Resolving uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com (uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com)... 162.125.6.6, 2620:100:601c:6::a27d:606\n",
      "Connecting to uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com (uc74b6836f4aa11c1e98898daedf.dl.dropboxusercontent.com)|162.125.6.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [application/binary]\n",
      "Saving to: ‘test.txt’\n",
      "\n",
      "test.txt            100%[===================>]   4.67M  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-05-20 11:28:27 (162 MB/s) - ‘test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train.txt https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "!wget -O test.txt https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Tokenization & Transform\n",
    "---\n",
    "Transform the dataset into the format that BERT can be trained on. \n",
    "\n",
    "### Get tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "bert_tokenizer = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "Input sentences must be converted to token index, token type, and valid length, which are necessary input vectors for BERT training. Token index is required to generate Token Embedding, token type is required for Sentence Embedding, and valid length is required to perform various operations internally. \n",
    "\n",
    "- ***Token Index***: The vocabulary index of each token is extracted and generated as a vector of a fixed length. We often refer to these vectors as `token_id`.\n",
    "For reference, some vocabulary indexes are already reserved (e.g., The vocabulary indexes of `[PAD], [CLS], [SEP], [MASK]` are 1, 2, 3, 4, respectively).\n",
    "- ***Token Type***: Since single sentence or two sentences can come in, token segment vectors are required to distinguish them if a token belongs to first sentence or the second sentence. We often refer to these vectors as `segment_id`. \n",
    "    - In the case of single sentence, the value of each token is always 0.\n",
    "    - In the case of two sentences, the token belonging to the first sentence is 0, and the token belonging to the second sentence is 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "[MASK] token id = 4\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary used for tokenization = \\n%s'%vocab)\n",
    "print('%s token id = %s'%(vocab.padding_token, vocab[vocab.padding_token]))\n",
    "print('%s token id = %s'%(vocab.cls_token, vocab[vocab.cls_token]))\n",
    "print('%s token id = %s'%(vocab.sep_token, vocab[vocab.sep_token]))\n",
    "print('%s token id = %s'%(vocab.mask_token, vocab[vocab.mask_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation is performed through the following procedures.\n",
    "\n",
    "- Tokenize the input sequences \n",
    "- Insert `[CLS]` token at the beginning \n",
    "- Insert `[SEP]` token between sentence A and sentence B, and at the end \n",
    "- Generate segment ids to indicate whether a token belongs to the first sequence or the second sequence. If the input sentence is not a pair, this value is always 0.\n",
    "- Generate valid length.\n",
    "\n",
    "Let's transform one sentence for test purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original === \n",
      "[['아 더빙.. 진짜 짜증나네요 목소리']]\n",
      "label: 0\n",
      "\n",
      "=== Transformed ===\n",
      "[(array([   2, 3093, 1698, 6456,  517,   54,  517,   54, 4368, 4396, 7316,\n",
      "       5655, 5703, 2073,    3,    1,    1,    1,    1,    1], dtype=int32), array(15, dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "def print_sample_transform(dataset, idx, bert_tokenizer, max_seq_length=20, pair=False):\n",
    "    sen = [[dataset[idx][0]]]\n",
    "    label = dataset[idx][1]\n",
    "    data_sample = gluon.data.SimpleDataset(sen)\n",
    "    transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_seq_length, pair=pair)\n",
    "    out = list(data_sample.transform(transform))\n",
    "    print('=== Original === ')\n",
    "    print(sen)\n",
    "    print('label: ' + label)\n",
    "    print('\\n=== Transformed ===')\n",
    "    print(out)\n",
    "        \n",
    "print_sample_transform(dataset_train, 0, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert all sententces. When converting multiple sentences, it is convenient to use the `BERTDatasetTransform()` function, which is published in the GluonNLP tutorial. The training and evaluation time varies depending on the `max_len` parameter. In this example, we recommend 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "all_labels = ['0','1']\n",
    "\n",
    "# for single sentence classification, set pair=False\n",
    "# for regression task, set class_labels=None\n",
    "# for inference without label available, set has_label=False\n",
    "transform = BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                                class_labels=all_labels,\n",
    "                                                has_label=True,\n",
    "                                                pad=True,\n",
    "                                                pair=False)\n",
    "data_train = dataset_train.transform(transform)\n",
    "data_test = dataset_test.transform(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check sample outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids = \n",
      "[   2 3093 1698 6456  517   54  517   54 4368 4396 7316 5655 5703 2073\n",
      "    3    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1]\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "valid length = \n",
      "15\n",
      "label = \n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "sample_id = 0\n",
    "print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "print('segment ids = \\n%s'%data_train[sample_id][1])\n",
    "print('valid length = \\n%s'%data_train[sample_id][2])\n",
    "print('label = \\n%s'%data_train[sample_id][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. Creating DataLoader and Trainer \n",
    "---\n",
    "We need to create an iterator for tha dataset using `DataLoader`. Iterators save memory during training because you don not have to load the entire dataset into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 * num_gpus\n",
    "num_epochs = 4\n",
    "max_grad_norm = 1\n",
    "log_interval = 50\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FixedBucketSampler()` assigns each data sample to a fixed bucket based on its length.\n",
    "Without the bucketing strategy, it is inefficient because one or two long sentences in each bucket can cause unnecessary padding.\n",
    "\n",
    "![no_bucket_strategy](./imgs/no_bucket_strategy.png)\n",
    "\n",
    "\n",
    "![fixed_bucket_strategy_ratio0.7](./imgs/fixed_bucket_strategy_ratio0.7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 0 ns, total: 22.8 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The FixedBucketSampler and the DataLoader for making the mini-batches\n",
    "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_train],\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "train_dataloader = gluon.data.DataLoader(data_train, batch_sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.57 s, sys: 0 ns, total: 7.57 s\n",
      "Wall time: 7.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_test],\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `gluon.Trainer()`. Gradient clipping to prevent the exploding gradient can be implemented during training, but can be used simply by specifying it when initializing the `gluon.Trainer()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_params = bert_classifier.collect_params()\n",
    "trainer = gluon.Trainer(all_model_params, 'adam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9, 'clip_gradient': 1}, \n",
    "                        kvstore='device')\n",
    "    \n",
    "# Weight Decay is not applied to LayerNorm and Bias.\n",
    "for _, v in bert_classifier.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "    v.wd_mult = 0.0\n",
    "    \n",
    "# Collect all differentiable parameters\n",
    "# `grad_req == 'null'` indicates no gradients are calculated (e.g. constant parameters)\n",
    "# The gradients for these params are clipped later\n",
    "params = [p for p in all_model_params.values() if p.grad_req != 'null']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. Fine-tuning the model\n",
    "---\n",
    "Now you can start fine-tuning the model with a few epochs. The code below is based on the [GluonNLP tutorial](https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html) and the [BERT Fine-tuning](https://mccormickml.com/2019/07/22/BERT-fine-tuning/). However, since both tutorials do not support multi-GPUs, the code has been slightly modified to enable multi-GPU training. <br>\n",
    "Training takes about 21 minutes to run on a `p3.8xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def evaluate_accuracy(model, data_iter, ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(tqdm(data_iter)):\n",
    "        \n",
    "        # Load the data to the GPUs\n",
    "        token_ids_ = gluon.utils.split_and_load(token_ids, ctx, even_split=False)\n",
    "        valid_length_ = gluon.utils.split_and_load(valid_length, ctx, even_split=False)\n",
    "        segment_ids_ = gluon.utils.split_and_load(segment_ids, ctx, even_split=False)\n",
    "        label_ = gluon.utils.split_and_load(label, ctx, even_split=False)\n",
    "\n",
    "        for t, v, s, l in zip(token_ids_, valid_length_, segment_ids_, label_):\n",
    "            # Forward computation\n",
    "            out = model(t, s, v.astype('float32'))\n",
    "            ls = loss_function(out, l).mean()\n",
    "            total_loss += ls.asscalar()\n",
    "            acc.update(preds=out, labels=l)\n",
    "        \n",
    "    avg_acc = acc.get()[1]\n",
    "    avg_loss = total_loss / batch_id\n",
    "    \n",
    "    print('Validation loss={:.4f}, acc={:.3f}'.format(avg_loss, avg_acc))\n",
    "\n",
    "    return avg_acc, avg_loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60688c17df2402d84ed6b0c2c2dcd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 50/592] loss=2.3405, lr=0.0000500, acc=0.678\n",
      "[Epoch 0 Batch 100/592] loss=1.8955, lr=0.0000500, acc=0.729\n",
      "[Epoch 0 Batch 150/592] loss=1.6426, lr=0.0000500, acc=0.760\n",
      "[Epoch 0 Batch 200/592] loss=1.4466, lr=0.0000500, acc=0.780\n",
      "[Epoch 0 Batch 250/592] loss=1.3675, lr=0.0000500, acc=0.794\n",
      "[Epoch 0 Batch 300/592] loss=1.4751, lr=0.0000500, acc=0.801\n",
      "[Epoch 0 Batch 350/592] loss=1.3329, lr=0.0000500, acc=0.809\n",
      "[Epoch 0 Batch 400/592] loss=1.2909, lr=0.0000500, acc=0.816\n",
      "[Epoch 0 Batch 450/592] loss=1.2136, lr=0.0000500, acc=0.822\n",
      "[Epoch 0 Batch 500/592] loss=1.2886, lr=0.0000500, acc=0.826\n",
      "[Epoch 0 Batch 550/592] loss=1.2262, lr=0.0000500, acc=0.830\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257eca239c224d4f8f9e601479c5a577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss=1.1565, acc=0.879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c003d5f581654e88b910eaa07f280f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 50/592] loss=1.0926, lr=0.0000500, acc=0.888\n",
      "[Epoch 1 Batch 100/592] loss=1.0264, lr=0.0000500, acc=0.891\n",
      "[Epoch 1 Batch 150/592] loss=1.1830, lr=0.0000500, acc=0.885\n",
      "[Epoch 1 Batch 200/592] loss=1.0743, lr=0.0000500, acc=0.886\n",
      "[Epoch 1 Batch 250/592] loss=1.0176, lr=0.0000500, acc=0.888\n",
      "[Epoch 1 Batch 300/592] loss=1.0182, lr=0.0000500, acc=0.889\n",
      "[Epoch 1 Batch 350/592] loss=1.0387, lr=0.0000500, acc=0.889\n",
      "[Epoch 1 Batch 400/592] loss=1.0263, lr=0.0000500, acc=0.890\n",
      "[Epoch 1 Batch 450/592] loss=1.0123, lr=0.0000500, acc=0.891\n",
      "[Epoch 1 Batch 500/592] loss=0.9843, lr=0.0000500, acc=0.892\n",
      "[Epoch 1 Batch 550/592] loss=1.0644, lr=0.0000500, acc=0.891\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced1a27efb054280af4c4675b60605b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss=1.0665, acc=0.890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e850ee221ce44c0a18c9def3d39990e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2 Batch 50/592] loss=0.8132, lr=0.0000500, acc=0.920\n",
      "[Epoch 2 Batch 100/592] loss=0.8058, lr=0.0000500, acc=0.920\n",
      "[Epoch 2 Batch 150/592] loss=0.8242, lr=0.0000500, acc=0.920\n",
      "[Epoch 2 Batch 200/592] loss=0.8477, lr=0.0000500, acc=0.919\n",
      "[Epoch 2 Batch 250/592] loss=0.9914, lr=0.0000500, acc=0.915\n",
      "[Epoch 2 Batch 300/592] loss=0.8334, lr=0.0000500, acc=0.916\n",
      "[Epoch 2 Batch 350/592] loss=0.8210, lr=0.0000500, acc=0.917\n",
      "[Epoch 2 Batch 400/592] loss=0.8663, lr=0.0000500, acc=0.916\n",
      "[Epoch 2 Batch 450/592] loss=0.9275, lr=0.0000500, acc=0.915\n",
      "[Epoch 2 Batch 500/592] loss=0.7771, lr=0.0000500, acc=0.915\n",
      "[Epoch 2 Batch 550/592] loss=0.8687, lr=0.0000500, acc=0.915\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cfc4047ce14b15bac1a11dd58995b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss=1.1556, acc=0.891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95223612a07b4644843481be1efbb5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 50/592] loss=0.6227, lr=0.0000500, acc=0.941\n",
      "[Epoch 3 Batch 100/592] loss=0.6630, lr=0.0000500, acc=0.939\n",
      "[Epoch 3 Batch 150/592] loss=0.7313, lr=0.0000500, acc=0.936\n",
      "[Epoch 3 Batch 200/592] loss=0.6676, lr=0.0000500, acc=0.935\n",
      "[Epoch 3 Batch 250/592] loss=0.6529, lr=0.0000500, acc=0.936\n",
      "[Epoch 3 Batch 300/592] loss=0.6622, lr=0.0000500, acc=0.936\n",
      "[Epoch 3 Batch 350/592] loss=0.6504, lr=0.0000500, acc=0.936\n",
      "[Epoch 3 Batch 400/592] loss=0.6530, lr=0.0000500, acc=0.936\n",
      "[Epoch 3 Batch 450/592] loss=0.7057, lr=0.0000500, acc=0.935\n",
      "[Epoch 3 Batch 500/592] loss=0.7444, lr=0.0000500, acc=0.935\n",
      "[Epoch 3 Batch 550/592] loss=0.6628, lr=0.0000500, acc=0.935\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9c11da9c7144db96153f24cb57e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss=1.1965, acc=0.893\n",
      "CPU times: user 35min 14s, sys: 10min 35s, total: 45min 49s\n",
      "Wall time: 21min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "training_stats = []\n",
    "step_num = 0\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_id in range(num_epochs):\n",
    "\n",
    "    # === Training phase ===\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()    \n",
    "    \n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(tqdm(train_dataloader)):\n",
    "        \n",
    "        # Load the data to the GPUs\n",
    "        token_ids_ = gluon.utils.split_and_load(token_ids, ctx, even_split=False)\n",
    "        valid_length_ = gluon.utils.split_and_load(valid_length, ctx, even_split=False)\n",
    "        segment_ids_ = gluon.utils.split_and_load(segment_ids, ctx, even_split=False)\n",
    "        label_ = gluon.utils.split_and_load(label, ctx, even_split=False)\n",
    "\n",
    "        losses = []\n",
    "        with autograd.record():\n",
    "\n",
    "            for t, v, s, l in zip(token_ids_, valid_length_, segment_ids_, label_):\n",
    "                # Forward computation\n",
    "                out = bert_classifier(t, s, v.astype('float32'))\n",
    "                ls = loss_function(out, l).mean()\n",
    "\n",
    "                losses.append(ls)\n",
    "                metric.update([l], [out])\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients        \n",
    "        for ls in losses:\n",
    "            ls.backward()  \n",
    "        \n",
    "        trainer.step(1)\n",
    "#         trainer.allreduce_grads()\n",
    "#         nlp.utils.clip_grad_global_norm(params, 1)\n",
    "#         trainer.update(1)\n",
    "\n",
    "        # Diff 5: sum losses over all devices\n",
    "        step_loss += sum([l.sum().asscalar() for l in losses])\n",
    "        total_loss += sum([l.sum().asscalar() for l in losses])    \n",
    "        #metric.update([label], [out])\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                         .format(epoch_id, batch_id + 1, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "            \n",
    "        train_avg_acc = metric.get()[1]\n",
    "        train_avg_loss = total_loss / batch_id\n",
    "        total_loss = 0\n",
    "    \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    train_time = format_time(time.time() - t0)\n",
    "    \n",
    "    # === Validation phase ===\n",
    "    \n",
    "    # Measure how long the validation epoch takes.    \n",
    "    t0 = time.time()    \n",
    "    valid_avg_acc, valid_avg_loss = evaluate_accuracy(bert_classifier, test_dataloader, ctx)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    valid_time = format_time(time.time() - t0)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "     # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_id + 1,\n",
    "            'train_acc': train_avg_acc,\n",
    "            'train_loss': train_avg_loss,\n",
    "            'train_time': train_time,\n",
    "            'valid_acc': valid_avg_acc,\n",
    "            'valid_loss': valid_avg_loss,\n",
    "            'valid_time': valid_time\n",
    "        }\n",
    "    )    \n",
    "    \n",
    "    # === Save Model Parameters ===\n",
    "    bert_classifier.save_parameters('{}/net_epoch{}.params'.format(output_dir, epoch_id))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. Evaluation\n",
    "---\n",
    "\n",
    "Let's take a brief look at the training results so far.\n",
    "Having a lot of epochs is not a good thing. As you can see in the graph and table, training metrics continue to decrease, but validation metrics decrease after some point.\n",
    "\n",
    "The validation accuracy is pretty good with 89~89.7%, which is slightly less than the 90.1% accuracy on the official site, but has not been hyperparameter tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_time</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0:04:24</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>1.1565</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0:04:22</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>1.0665</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0:04:22</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>1.1556</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0:04:22</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>1.1965</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_acc  train_loss train_time  valid_acc  valid_loss valid_time\n",
       "epoch                                                                    \n",
       "1         0.8331      0.0022    0:04:24     0.8795      1.1565    0:00:58\n",
       "2         0.8910      0.0014    0:04:22     0.8897      1.0665    0:00:58\n",
       "3         0.9153      0.0016    0:04:22     0.8906      1.1556    0:00:58\n",
       "4         0.9346      0.0009    0:04:22     0.8934      1.1965    0:00:58"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_stats(df_stats, num_epochs=5):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Use plot styling from seaborn.\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    # Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.2)\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,6)\n",
    "\n",
    "    xticks = list(range(1, num_epochs+1))\n",
    "\n",
    "    plt.subplot(221)\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1.plot(df_stats['train_loss'], 'b-o', label=\"Training\")\n",
    "    ax1.plot(df_stats['valid_loss'], 'g-o', label=\"Validation\")\n",
    "    ax1.set_xticks(xticks)     \n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    ax2.plot(df_stats['train_acc'], 'b-o', label=\"Training\")\n",
    "    ax2.plot(df_stats['valid_acc'], 'g-o', label=\"Validation\")\n",
    "    ax2.set_xticks(xticks) \n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "plot_training_stats(df_stats, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all but the best performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_stats['valid_acc'].argmax() - 1\n",
    "save_filename = 'net_epoch{}.params'.format(idx)\n",
    "\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('params'):\n",
    "        if filename == save_filename:\n",
    "            os.rename(os.path.join(output_dir, filename), os.path.join(output_dir, 'net_nsmc.params'))\n",
    "        else:\n",
    "            os.remove(os.path.join(output_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to deploy the fine-tuned model to the SageMaker Endpoint, please copy the `.spiece` file to the model parameter folder and compress them with `model.tar.gz`.\n",
    "\n",
    "```bash\n",
    "# Example shell scripts\n",
    "$ cp ~/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece ./model_save/.\n",
    "$ cd model_save\n",
    "$ tar cvfz model.tar.gz ./*.params ./*.spiece\n",
    "$ aws s3 cp ./model.tar.gz s3://<your-bucket-name>/kobert-model/model.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_save/net_nsmc.params\n",
      "./model_save/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "!cp ~/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece ./model_save/.\n",
    "!tar cvfz ./model_save/model.tar.gz ./model_save/*.params ./model_save/*.spiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] GluonNLP Tutorial. Fine-tuning Sentence Pair Classification with BERT, <https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html>.\n",
    "\n",
    "[5] Chris McCormick. BERT Fine-Tuning Tutorial with PyTorch, <https://mccormickml.com/2019/07/22/BERT-fine-tuning>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
